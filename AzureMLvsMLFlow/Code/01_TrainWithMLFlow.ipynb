{"cells":[{"cell_type":"code","source":["import mlflow\nfrom mlflow.tracking import MlflowClient\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline\nimport datetime as dt\nfrom pyspark.ml.feature import OneHotEncoder, VectorAssembler"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["%scala\nval tags = com.databricks.logging.AttributionContext.current.tags\nval username = tags.getOrElse(com.databricks.logging.BaseTagDefinitions.TAG_USER, java.util.UUID.randomUUID.toString.replace(\"-\", \"\"))\nspark.conf.set(\"com.databricks.demo.username\", username)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tags: Map[com.databricks.logging.TagDefinition,String] = Map(TagDefinition(opId,) -&gt; HttpServer-6fa0b428ebacab82, TagDefinition(opTarget,) -&gt; /notebook/1500231256277984/command/1500231256277997, TagDefinition(clusterMemory,) -&gt; 18432, TagDefinition(notebookId,) -&gt; 1500231256277984, TagDefinition(projectName,) -&gt; webapp, TagDefinition(eventWindowTime,) -&gt; 6016597.85000002, TagDefinition(httpTarget,) -&gt; /notebook/1500231256277984/command/1500231256277997, TagDefinition(buildHash,) -&gt; &quot;&quot;, TagDefinition(browserHash,) -&gt; #notebook/1500231256277984/command/1500231256277999, TagDefinition(host,Host where the request is coming from.) -&gt; 10.139.64.5, TagDefinition(notebookLanguage,) -&gt; python, TagDefinition(sparkVersion,) -&gt; 5.3.x-scala2.11, TagDefinition(hostName,) -&gt; cons-webapp-0, TagDefinition(httpMethod,) -&gt; POST, TagDefinition(browserIdleTime,) -&gt; 2064, TagDefinition(browserTabId,) -&gt; afdb42f8-a5bb-4827-bda7-41e026cb4520, TagDefinition(sourceIpAddress,) -&gt; 73.193.17.210, TagDefinition(browserUserAgent,) -&gt; Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36, TagDefinition(orgId,) -&gt; 1559977908724754, TagDefinition(userAgent,) -&gt; Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36, TagDefinition(clusterId,) -&gt; 0703-220934-empty762, TagDefinition(rootOpId,Unique identifier for a root of a trace (tree of ops).) -&gt; 7776927338635621033_6765987163455679120_ac80bf1b6714425cbf23248de5803c9c, TagDefinition(sessionId,) -&gt; cb5ebdf37f0ec6186cfcff06aeb65e75c192aad6f8a3fb73555a6bd649d95ccc, TagDefinition(clusterCreator,) -&gt; Webapp, TagDefinition(clientBranchName,) -&gt; 2.102.1091, TagDefinition(clusterType,) -&gt; spot, TagDefinition(browserHasFocus,) -&gt; true, TagDefinition(userId,) -&gt; 8499602646880646, TagDefinition(browserIsHidden,) -&gt; false, TagDefinition(opType,) -&gt; HttpServer, TagDefinition(user,) -&gt; ryan.chynoweth@insight.com, TagDefinition(browserHostName,) -&gt; westus.azuredatabricks.net, TagDefinition(parentOpId,) -&gt; ServiceMain-6fa0b428e2bf0002, TagDefinition(jettyRpcType,) -&gt; &quot;com.databricks.backend.common.rpc.InternalDriverBackendMessages$DriverBackendRequest&quot;)\nusername: String = ryan.chynoweth@insight.com\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["client = MlflowClient() # client\nexps = client.list_experiments() # get all experiments"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["exp = [s for s in exps if \"/Users/{}/AzureML_MLFlow/MLFlowExp\".format(spark.conf.get(\"com.databricks.demo.username\")) in s.name][0] # get only the exp we want\nexp_id = exp.experiment_id # save exp id to variable\nartifact_location = exp.artifact_location # artifact location for storing\nrun = client.create_run(exp_id) # create the run\nrun_id = run.info.run_id # get the run id"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# start and mlflow run\nmlflow.start_run(run_id)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["spark.read.format(\"csv\").option(\"inferSchema\", \"True\").option(\"header\", \"True\").load(\"/databricks-datasets/bikeSharing/data-001/day.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>DataFrame[instant: int, dteday: timestamp, season: int, yr: int, mnth: int, holiday: int, weekday: int, workingday: int, weathersit: int, temp: double, atemp: double, hum: double, windspeed: double, casual: int, registered: int, cnt: int]\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["try: \n  df = (spark\n        .read\n        .format(\"csv\")\n        .option(\"inferSchema\", \"True\")\n        .option(\"header\", \"True\")\n        .load(\"/databricks-datasets/bikeSharing/data-001/day.csv\")\n       )\n  # split data\n  train_df, test_df = df.randomSplit([0.7, 0.3])\n\n  # One Hot Encoding\n  mnth_encoder = OneHotEncoder(inputCol=\"mnth\", outputCol=\"encoded_mnth\")\n  weekday_encoder = OneHotEncoder(inputCol=\"weekday\", outputCol=\"encoded_weekday\")\n\n  # set the training variables we want to use\n  train_cols = ['encoded_mnth', 'encoded_weekday', 'temp', 'hum']\n\n  # convert cols to a single features col\n  assembler = VectorAssembler(inputCols=train_cols, outputCol=\"features\")\n\n  # Set linear regression model\n  lr = LinearRegression(featuresCol=\"features\", labelCol=\"cnt\")\n\n  # Create pipeline\n  pipeline = Pipeline(stages=[\n      mnth_encoder,\n      weekday_encoder,\n      assembler,\n      lr\n  ])\n\n  # fit pipeline\n  lrPipelineModel = pipeline.fit(train_df)\n\n  # write model to datetime folder and latest folder\n  lrPipelineModel.write().overwrite().save(\"{}/latest/bike_sharing_model.model\".format(artifact_location))\n  lrPipelineModel.write().overwrite().save(\"{}/year={}/month={}/day={}/bike_sharing_model.model\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n\n  # write test predictions to datetime and lastest folder\n  predictions = lrPipelineModel.transform(test_df)\n  predictions.write.format(\"parquet\").mode(\"overwrite\").save(\"{}/latest/test_predictions.parquet\".format(artifact_location))\n  predictions.write.format(\"parquet\").mode(\"overwrite\").save(\"{}/year={}/month={}/day={}/test_predictions.parquet\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n\n  # mlflow log evaluations\n  evaluator = RegressionEvaluator(labelCol = \"cnt\", predictionCol = \"prediction\")\n\n  mlflow.log_metric(\"mae\", evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"}))\n  mlflow.log_metric(\"rmse\", evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"}))\n  mlflow.log_metric(\"r2\", evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"}))\n  mlflow.set_tag(\"Model Path\", \"{}/year={}/month={}/day={}\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n\n  mlflow.end_run(status=\"FINISHED\")\n  print(\"Model training finished successfully\")\nexcept Exception as e:\n  mlflow.log_param(\"Error\", str(e))\n  mlflow.end_run(status=\"FAILED\")\n  print(\"Model training failed: {}\".format(str(e)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">399193c422da474ab5bdcd48ada5da04\nModel training finished successfully\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"01_TrainWithMLFlow","notebookId":1500231256277984},"nbformat":4,"nbformat_minor":0}
